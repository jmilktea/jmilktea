## 问题   
生产上使用kafka做消息通信，有一个服务重启时，发现会消费以前的消息，导致消息重复消费。  
问题的关键在于**重启**两字，没重启时消息的消费是正常的。这个问题可不小，如果消费者没有做好消息的幂等性，可能导致数据异常。
就算做了幂等性，每次这么重复消费也容易出现问题，不好排查。

我们kafka server的版本使用的是2.11-1.1.0。消费者的配置非常简单，其中一个主要的配置是auto-offset-reset，我们看它的解释是
```
/**
* What to do when there is no initial offset in Kafka or if the current offset no
* longer exists on the server.
*/
autoOffsetReset
```
这是描述kafka上没有初始偏移量，或者偏移量不存在时，如何消费消息。可取的值有：
- earliest
如果存在已提交的offset，则从最新的offset开始消费。如果不存在已提交的offset，则从还保留着的最早的消息开始消费
- latest
如果存在已提交的offset，则从最新的offset开始消费。如果不存在已提交的offset，则从最新的消息开始消费。这是默认值。
- exception  
抛出异常  
- none  
各分区存在已提交的offset，则从最新的offset开始消费。如果有一个分区不存在已提交的offset，则抛出异常。

比较常用的是earliest和latest，我们项目中使用的是earliest。

## 问题复现
按照如下步骤复现问题
1. 下载对应版本的kafka，[下载地址](http://kafka.apache.org/downloads)，为了简单起见，我们使用windows的版本
2. 解压后，找到bin/windows/kafka-zookeeper-bat，使用命令启动zk
```
 .\zookeeper-server-start.bat ../../config/zookeeper.properties
```
3. 找到config/server.properties，这个是kafka的配置，新增配置offsets.retention.minutes=1。接受使用命令启动kafka server
```
.\kafka-server-start.bat ..\..\config\server.properties
```
4. 创建test topic
```
.\kafka-topics.bat --create --zookeeper localhost:2181 --partitions 1 --replication-factor 1 --topic test
```
5. 查看test topic
```
 .\kafka-topics.bat --list --zookeeper localhost:2181
```

我们往test topic发送几条消息，消费者代码非常简单，可以打印出消息内容
```
@KafkaListener(topics = "test")
public void receive(ConsumerRecord<String, String> consumerRecord) {
    System.out.println("kafka:" + consumerRecord.value());
}
```
**过几分钟后**,我们重启消费者服务，可以发现，消息又打了一遍...，问题得以复现。

## 分析  
上面步骤的关键是我们配置了offsets.retention.minutes=1。这个参数的默认值是1440，单位是分钟，也就是1天。上面我们配置了1分钟是为了快速观察效果。    
实际上kafka会把消费者消费消息的偏移量记录在内部的topic中，命名格式为：_consumer_offset-数字。当我们服务启动时，会根据group id去kafka server获取到这个offset的值，保存在消费者端，称为fetch offset，然后再根据fetch offset去broker拉取消息消费。  
问题是kafka是会定期清理consumer offset这个数据的，也就是当消费者长期没有消息消费，kafka会认为这个消费者已经下线了，然后它就会把consumer offset清掉。也就是根据offsets.retention.minutes配置，我们可以看到kafka server打印的日志，它确实在定期检查  
![image](https://github.com/jmilktea/jmilktea/blob/master/%E4%B8%AD%E9%97%B4%E4%BB%B6/kafka/images/kafka-remove-offset.png)  
当consumer offset被清理后，消费者重启重启再去获取时，就拿不到offset，就会根据auto-offset-reset配置决定如何消费消息，由于我们配置了earliest,就会从开始重复消费消息。  

问题找到了，那么如何解决呢？
1. offsets.retention.minutes设置成永久或消息过期时间(log.retention.minutes)的2倍  
仔细想想，消费者下线去清理offset的场景确实不多，那么我们可以不做这个清理，把这个时间设置成一个永久的数字即可。   
或者设置成消息过期时间的2倍也是一种常见做法，就算consumer offset被清理了，重新消费，消息也已经过期删掉了，不会重复消费。 
2. 消费者自己记录fetch offset，不依赖consumer offset  
消费者可以在消费后把offset记录下来，例如保存到数据库，下次启动时，调用api设置fetch offset，这样就不依赖kafka server的offset了。这种方式的缺点是需要自己编码去实现逻辑。  
3. 做好幂等性  
消息重复消费是无法避免了，所以做好幂等性是一个基本要求。可以给消息加一个唯一id，消费后缓存到redis，每次消费前先判断是否存在redis，存在则拒绝。这样就算发生上面的情况也不会有影响。这种方式的缺点是可能需要缓存比较多的数据，而且缓存的时间依赖于kafka消息过期时间，不好控制。

